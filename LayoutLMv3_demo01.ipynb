{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'paddleocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m LayoutLMForTokenClassification, LayoutLMTokenizerFast\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mloader\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Structured_Document_-Extracting/loader.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Loader\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/Documents/GitHub/Structured_Document_-Extracting/utils.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# utils\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaddleocr\u001b[39;00m \u001b[39mimport\u001b[39;00m PaddleOCR\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paddleocr'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from transformers import LayoutLMForTokenClassification, LayoutLMTokenizerFast\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from loader import *\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the pre-trained LayoutLM model and tokenizer\n",
    "model = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "tokenizer = LayoutLMTokenizerFast.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 读取JSON文件\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m dataSet(\u001b[39m'\u001b[39m\u001b[39mdata/01.json\u001b[39m\u001b[39m'\u001b[39m,processor)\n\u001b[1;32m      3\u001b[0m dataload \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(data,batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataSet' is not defined"
     ]
    }
   ],
   "source": [
    "# 读取JSON文件\n",
    "data = dataSet('data/01.json',processor)\n",
    "dataload = torch.utils.data.DataLoader(data,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ocr': '/data/upload/6/e1b02bcd-01.png',\n",
       "  'id': 1,\n",
       "  'bbox': [{'x': 4.786641929499072,\n",
       "    'y': 2.5174825174825175,\n",
       "    'width': 53.02126444983588,\n",
       "    'height': 6.8531468531468525,\n",
       "    'rotation': 0,\n",
       "    'original_width': 882,\n",
       "    'original_height': 774},\n",
       "   {'x': 29.210789210789205,\n",
       "    'y': 23.916083916083917,\n",
       "    'width': 45.779934351362925,\n",
       "    'height': 5.734265734265733,\n",
       "    'rotation': 0,\n",
       "    'original_width': 882,\n",
       "    'original_height': 774}],\n",
       "  'label': [{'x': 4.786641929499072,\n",
       "    'y': 2.5174825174825175,\n",
       "    'width': 53.02126444983588,\n",
       "    'height': 6.8531468531468525,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 2'],\n",
       "    'original_width': 882,\n",
       "    'original_height': 774},\n",
       "   {'x': 29.210789210789205,\n",
       "    'y': 23.916083916083917,\n",
       "    'width': 45.779934351362925,\n",
       "    'height': 5.734265734265733,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 1'],\n",
       "    'original_width': 882,\n",
       "    'original_height': 774}],\n",
       "  'transcription': ['Full name: PETER ALLAN NOAD',\n",
       "   'Email: noadies@xtra.co.nz'],\n",
       "  'annotator': 1,\n",
       "  'annotation_id': 5,\n",
       "  'created_at': '2023-11-28T21:52:33.946856Z',\n",
       "  'updated_at': '2023-11-28T21:53:07.371461Z',\n",
       "  'lead_time': 62.225},\n",
       " {'ocr': '/data/upload/6/b91ff0ad-02.png',\n",
       "  'id': 2,\n",
       "  'bbox': [{'x': 26.671717740531797,\n",
       "    'y': 22.377622377622377,\n",
       "    'width': 23.577798482630108,\n",
       "    'height': 5.454545454545453,\n",
       "    'rotation': 0,\n",
       "    'original_width': 1366,\n",
       "    'original_height': 1042},\n",
       "   {'x': 6.294525386765505,\n",
       "    'y': 0.5594405594405595,\n",
       "    'width': 77.98810267331498,\n",
       "    'height': 5.734265734265735,\n",
       "    'rotation': 0,\n",
       "    'original_width': 1366,\n",
       "    'original_height': 1042}],\n",
       "  'label': [{'x': 26.671717740531797,\n",
       "    'y': 22.377622377622377,\n",
       "    'width': 23.577798482630108,\n",
       "    'height': 5.454545454545453,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 1'],\n",
       "    'original_width': 1366,\n",
       "    'original_height': 1042},\n",
       "   {'x': 6.294525386765505,\n",
       "    'y': 0.5594405594405595,\n",
       "    'width': 77.98810267331498,\n",
       "    'height': 5.734265734265735,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 2'],\n",
       "    'original_width': 1366,\n",
       "    'original_height': 1042}],\n",
       "  'transcription': ['Email: -', 'Full name: TAMATEA BASIE VIVERS TANGITU'],\n",
       "  'annotator': 1,\n",
       "  'annotation_id': 6,\n",
       "  'created_at': '2023-11-28T21:54:03.670177Z',\n",
       "  'updated_at': '2023-11-28T21:54:03.670191Z',\n",
       "  'lead_time': 48.302},\n",
       " {'ocr': '/data/upload/6/469349c1-03.png',\n",
       "  'id': 3,\n",
       "  'bbox': [{'x': 6.897189912265289,\n",
       "    'y': 2.937062937062937,\n",
       "    'width': 35.538063276756745,\n",
       "    'height': 5.874125874125875,\n",
       "    'rotation': 0,\n",
       "    'original_width': 1194,\n",
       "    'original_height': 998},\n",
       "   {'x': 28.407070316618054,\n",
       "    'y': 23.216783216783217,\n",
       "    'width': 48.39723090979373,\n",
       "    'height': 6.993006993006993,\n",
       "    'rotation': 0,\n",
       "    'original_width': 1194,\n",
       "    'original_height': 998}],\n",
       "  'label': [{'x': 6.897189912265289,\n",
       "    'y': 2.937062937062937,\n",
       "    'width': 35.538063276756745,\n",
       "    'height': 5.874125874125875,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 2'],\n",
       "    'original_width': 1194,\n",
       "    'original_height': 998},\n",
       "   {'x': 28.407070316618054,\n",
       "    'y': 23.216783216783217,\n",
       "    'width': 48.39723090979373,\n",
       "    'height': 6.993006993006993,\n",
       "    'rotation': 0,\n",
       "    'labels': ['Label 1'],\n",
       "    'original_width': 1194,\n",
       "    'original_height': 998}],\n",
       "  'transcription': ['Full name: Tiffany Ormsby',\n",
       "   'Email: ormsbytiffany@gmail.com'],\n",
       "  'annotator': 1,\n",
       "  'annotation_id': 7,\n",
       "  'created_at': '2023-11-28T21:54:52.743150Z',\n",
       "  'updated_at': '2023-11-28T21:54:52.743167Z',\n",
       "  'lead_time': 47.065}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = []\n",
    "for item in data:\n",
    "    for annotation in item.get('annotations', []):\n",
    "        for result in annotation.get('result', []):\n",
    "            if 'labels' in result.get('value', {}):\n",
    "                labels_text = ' '.join(result['value']['labels'])  # 将标签信息连接成文本\n",
    "                text_inputs.append(labels_text)\n",
    "\n",
    "# 将文本输入编码成模型可接受的格式\n",
    "inputs = tokenizer(text_inputs, return_tensors=\"pt\", padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据集和评估数据集\n",
    "# 这里可能需要根据数据量和训练需求进行拆分\n",
    "train_dataset = inputs[:2]\n",
    "eval_dataset = inputs[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the training arguments for the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Directory to save the training results\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "    per_device_train_batch_size=8,  # Batch size for training\n",
    "    per_device_eval_batch_size=8,  # Batch size for evaluation\n",
    "    warmup_steps=500,  # Number of warmup steps\n",
    "    weight_decay=0.01,  # Weight decay coefficient\n",
    "    logging_dir=\"./logs\",  # Directory to save logs\n",
    ")\n",
    "\n",
    "# 使用trainer训练模型\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa6e551b7394879b78565b19df28a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Encoding' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 开始训练\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/trainer.py:1838\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1837\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1838\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1839\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1840\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/accelerate/data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[1;32m    452\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/trainer_utils.py:755\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[\u001b[39mdict\u001b[39m]):\n\u001b[1;32m    754\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_columns(feature) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator(features)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_call(features)\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:305\u001b[0m, in \u001b[0;36mDataCollatorForTokenClassification.torch_call\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtorch_call\u001b[39m(\u001b[39mself\u001b[39m, features):\n\u001b[1;32m    303\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m     label_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mkeys() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     labels \u001b[39m=\u001b[39m [feature[label_name] \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features] \u001b[39mif\u001b[39;00m label_name \u001b[39min\u001b[39;00m features[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     no_labels_features \u001b[39m=\u001b[39m [{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m feature\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m label_name} \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Encoding' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
